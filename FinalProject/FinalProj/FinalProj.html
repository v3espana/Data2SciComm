<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">


<!--
Font-awesome icons ie github or twitter
-->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/brands.css" integrity="sha384-n9+6/aSqa9lBidZMRCQHTHKJscPq6NW4pCQBiMmHdUCvPN8ZOg2zJJTkC7WIezWv" crossorigin="anonymous">

<!--
Google fonts api stuff
-->



<title>Predicting Cognitive States Through EEG Sensors and Machine Learning</title>






<style>
@page {
size: 45in 38in;
margin: 0;
padding: 0;
}
body {
margin: 0;
font-size: 45px;
width: 45in;
height: 38in;
padding: 0;
text-align: justify;
font-family: Palatino;
}
.poster_wrap {
width: 45in;
height: 38in;
padding: 0cm;
}
.title_container {
width: 45in;
height: calc(38in * 0.15);
overflow: hidden;
background-color: #0b4545;
border: 0 solid #0b4545;
}
.logo_left {
float: left;
width: 10%;
height: 100%;
background-color: #0b4545;
display: flex;
align-items: center;
justify-content: center;
}
.logo_right {
float: right;
width: 10%;
height: 100%;
background-color: #0b4545;
display: flex;
align-items: center;
justify-content: center;
}
.poster_title {
text-align: center;
position: relative;
float: left;
width: 80%;
height: 100%;
color: #FFFFFF;
top: 50%;
transform: translateY(-50%);
-webkit-transform: translateY(-50%);
}
#title {
font-family: Palatino;
}
/* unvisited link */
a:link {
color: #cc0000;
}
.mybreak {
  break-before: column;
}
/* visited link */
a:visited {
color: #cc0000;
}

/* mouse over link */
a:hover {
color: #cc0000;
}

/* selected link */
a:active {
color: #cc0000;
}
.poster_body {
-webkit-column-count: 3; /* Chrome, Safari, Opera */
-moz-column-count: 3; /* Firefox */
column-count: 3;
-webkit-column-fill: auto;
-moz-column-fill: auto;
column-fill: auto;
-webkit-column-rule-width: 1mm;
-moz-column-rule-width: 1mm;
column-rule-width: 1mm;
-webkit-column-rule-style: dashed;
-moz-column-rule-style: dashed;
column-rule-style: dashed;
-webkit-column-rule-color: #0b4545;
-moz-column-rule-color: #0b4545;
column-rule-color: #0b4545;
column-gap: 1em;
padding-left: 0.5em;
padding-right: 0.5em;
height: 100%;
color: #000000
background-color: #ffffff;
}
.poster_title h1 {
font-size: 75pt;
margin: 0;
border: 0;
font-weight: normal;
}
.poster_body_wrap{
width: calc(45in + 0 + 0);
height: calc(38in * 0.83);
padding-top: calc(38in * 0.005);
padding-bottom: calc(38in * 0.01);
background-color: #ffffff;
}
.poster_title h3 {
color: #ffffff;
font-size: 50pt;
margin: 0;
border: 0;
font-weight: normal;
}
.poster_title h3 > sup {
  font-size: 35pt;
  margin-left: 0.02em;
}
.poster_title h5 {
color: #FFFFFF;
font-size: 35pt;
margin: 0;
border: 0;
font-weight: normal;
}
img {
margin-top: 2cm;
margin-bottom: 0;
}
.section {
  padding: 0.2em;
}
.poster_body h1 {
text-align: center;
color: #FFFFFF;
font-size: 65pt;
border: 2mm solid #0b4545;
background-color: #0b4545;
border-radius: 4mm 0mm;
margin-top: 2mm;
margin-bottom: 2mm;
font-weight: normal;
}
.poster_body h2 {
color: #000000;
font-size: 40pt;
padding-left: 4mm;
font-weight: normal;
}
.span {
width: 200%;
}
/* center align leaflet map,
from https://stackoverflow.com/questions/52112119/center-leaflet-in-a-rmarkdown-document */
.html-widget {
margin: auto;
position: sticky;
margin-top: 2cm;
margin-bottom: 2cm;
}
.leaflet.html-widget.html-widget-static-bound.leaflet-container.leaflet-touch.leaflet-fade-anim.leaflet-grab.leaflet-touch-drag.leaflet-touch-zoom {
position: sticky;
width: 100%;
}
pre.sourceCode.r {
background-color: #dddddd40;
border-radius: 4mm;
padding: 4mm;
width: 75%;
/* align-items: center; */
margin: auto;
padding-left: 2cm;
}
code.sourceCode.r{
background-color: transparent;
font-size: 20pt;
border-radius: 2mm;
}
.caption {
font-size: 25pt;
}
.table caption {
font-size: 25pt;
padding-bottom: 3mm;

}
code {
font-size: 1em;
font-family: monospace;
background-color: #00808024;
color: #0b4545;
padding: 1.2mm;
border-radius: 2mm;
}
.poster_title code {
font-size: 1em;
}
table {
font-size: 40px;
margin: auto;
border-top: 3px solid #666;
border-bottom: 3px solid #666;
}
table thead th {
border-bottom: 3px solid #ddd;
}
td {
padding: 8px;
}
th {
padding: 15px;
}
caption {
margin-bottom: 10px;
}
.poster_body p {
margin-right: 4mm;
margin-left: 4mm;
margin-top: 6mm;
margin-bottom: 10mm;
}
.poster_body ol {
margin-right: 4mm;
margin-left: 4mm;
}
#ul {
margin-right: 4mm;
margin-left: 4mm;
}
.references p {
font-size: 20pt;
}
.orcid img {
  width: 1em;
}
</style>
</head>
<body>


<div class="poster_wrap">
<div class="title_container">
<!-- Left Logo  -->
<div class="logo_left">
</div>
<!-- Poster Title -->
<div class= "poster_title">
<h1 id="title">Predicting Cognitive States Through EEG Sensors and Machine Learning</h1>
<h3 id="author">Vincent Espana<sup>1</sup></h3><br>
<h5 id="affiliation"><sup>1</sup> Department of Cognitive Science, Rutgers University</h5>
</div>
<!-- Right Logo  -->
<div class="logo_right">
</div>
</div>

<div class='poster_body_wrap'>
<div class='poster_body'>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>As AI technologies and machine learning continue to advance, its integration into everyday life has exponentially increased in recent years. This research investigates brainwave activity for machine learning models to better predict cognitive states using EEG sensors. Identifying patterns could improve AI decision-making systems, such as Tesla Autopilot and Full Self-Driving whose semi-autonomous technologies allows cars to accelerate, make turns, and even parallel park, all the while tracking the driver’s cognitive state <span class="citation">(Tesla Support n.d.)</span>.</p>
</div>
<div id="research-questions" class="section level1">
<h1>Research Questions</h1>
<p>How do <strong>variations</strong> in EEG sensor values between open and closed eye states reflect changes in brainwave activities, and how can this information be used to train machine learning models for <strong>accurately predicting</strong> cognitive states like attention and mental fatigue?</p>
<p>More specifically, this research aims to determine which sensors are <strong>most predictive</strong> of cognitive state during open and closed eye states.</p>
</div>
<div id="data-source" class="section level1">
<h1>Data Source</h1>
<p>The dataset used in this study is the <em>EEG Eye State</em> database from the UC Irvine Machine Learning Repository. It contains EEG recordings from <strong>14</strong> different electroencephalogram (EEG) sensors, in which participants were asked to perform tasks with either their eyes <strong>open</strong> (0) or <strong>closed</strong> (1) <span class="citation">(Roesler 2013)</span>. These sensors are positioned on different areas of the head to measure brainwave activity corresponding to various brain lobes. Each lobe has distinct functions <span class="citation">(Jawabri and Sharma 2023)</span>:</p>
<ul>
<li>Frontal Lobe: Responsible for decision-making, emotion regulation, and attention</li>
<li>Fronto-Central Lobe: Plays a key role in motor control</li>
<li>Temporal Lobe: Involved in hearing, language recognition, and memory</li>
<li>Parietal Lobe: Processes sensory information, such as touch, temperature, pressure, and pain</li>
<li>Occipital Lobe: Specializes in visual processing</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:eeg-image"></span>
<img src="electrodespos.png" alt="EEG Sensors by Emotiv [@hou2015electrodes]"  />
<p class="caption">
Figure 1: EEG Sensors by Emotiv <span class="citation">(Hou 2015)</span>
</p>
</div>
</div>
<div id="results-and-interpretation" class="section level1">
<h1>Results and Interpretation</h1>
<p><em>Prior to figure creation, the data was cleaned to remove significant outliers that were affecting the overall findings of this research. The data was not altered or changed in any way during cleaning. Plots were created using</em> <strong>tidyverse</strong> <em>and</em> <strong>ggplot</strong> <em>packages <span class="citation">(Wickham 2023; Wickham et al. 2024)</span>.</em></p>
<ol style="list-style-type: decimal">
<li>Does average EEG sensor values between eye states vary across the different sensors?</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot1"></span>
<img src="FinalProj_files/figure-html/plot1-1.png" alt="Average EEG Values Across Sensors Separated By Eye State" width="960" />
<p class="caption">
Figure 2: Average EEG Values Across Sensors Separated By Eye State
</p>
</div>
<p>This plot compares the mean signal value of each sensor for both open and closed eye states. Excluding the F8 sensor, the average signal value for all sensors for open eye states were less than or equal to the average signal value for closed eye states. The AF3, F4, F8, and FC6 sensors exhibit significant differences in mean sensor values, suggesting their importance in distinguishing cognitive states.</p>
<ol start="2" style="list-style-type: decimal">
<li>Are the visual processing (O1 and O2) sensors indicative of cognitive state?</li>
</ol>
<table>
<caption><span id="tab:table">Table 1: </span>Summary Statistics for Sensors O1 and O2</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Min.</th>
<th align="right">Max.</th>
<th align="right">Mean</th>
<th align="right">Std. Dev.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">O1 Open</td>
<td align="right">4027.18</td>
<td align="right">4178.46</td>
<td align="right">4071.973</td>
<td align="right">17.80437</td>
</tr>
<tr class="even">
<td align="left">O1 Closed</td>
<td align="right">4026.15</td>
<td align="right">4167.18</td>
<td align="right">4073.866</td>
<td align="right">24.14483</td>
</tr>
<tr class="odd">
<td align="left">O2 Open</td>
<td align="right">4567.18</td>
<td align="right">4731.79</td>
<td align="right">4614.925</td>
<td align="right">18.21651</td>
</tr>
<tr class="even">
<td align="left">O2 Closed</td>
<td align="right">4567.69</td>
<td align="right">4770.26</td>
<td align="right">4616.872</td>
<td align="right">18.53288</td>
</tr>
</tbody>
</table>
<p>This table provides summary statistics for the O1 and O2 sensors, which are specific to visual processing. The resulting values contained in this table do not provide any indication of whether or not these sensors are particularly important when predicting cognitive state, as the minimums, maximums, and means were similar across eye states. The standard deviation of the O1 sensor indicates that the underlying distributions may be significant.</p>
<ol start="3" style="list-style-type: decimal">
<li>What do frontal lobe sensors tell us and how can this information be used to by machine learning models to predict cognitive state?</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot2"></span>
<img src="FinalProj_files/figure-html/plot2-1.png" alt="Median Signal Value and Variability of AF3 Sensor" width="960" />
<p class="caption">
Figure 3: Median Signal Value and Variability of AF3 Sensor
</p>
</div>
<p>This plot further investigates the AF3 sensor. This sensor tells us that the range of signal values may be more significant that the mean signal value.</p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>Results consistently demonstrate that closed eye states produced a slightly higher mean signal value compared to open eye states. For many of the frontal lobe sensors (AF3, AF4, F8, FC6), a lower signal value for open states suggests reduced frontal lobe activity as cognitive process are more focused on visual inputs. Additionally, open eye states exhibit a wider signal range than closed eye states. For machine learning systems to accurately predict cognitive state, the variability in signal range between open and closed eye states may aid in distinguishing focus, attention, and fatigue. These findings can drastically improve semi-autonomous AI driving systems, hopefully reducing fatigue-related accidents. Continued research using EEG sensors in active-driving scenarios could further enhance cognitive state prediction models.</p>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-hou2015electrodes" class="csl-entry">
Hou, X. 2015. <span>“Location of 14 Electrodes of Emotiv EEG Device.”</span> <a href="https://www.researchgate.net/figure/Location-of-14-electrodes-of-Emotiv-EEG-device_fig1_283441559">https://www.researchgate.net/figure/Location-of-14-electrodes-of-Emotiv-EEG-device_fig1_283441559</a>.
</div>
<div id="ref-jawabri2023cerebral" class="csl-entry">
Jawabri, K. H., and S. Sharma. 2023. <span>“Physiology, Cerebral Cortex Functions.”</span> In <em>StatPearls [Internet]</em>. StatPearls Publishing. <a href="https://www.ncbi.nlm.nih.gov/books/NBK538496/">https://www.ncbi.nlm.nih.gov/books/NBK538496/</a>.
</div>
<div id="ref-roesler2013eeg" class="csl-entry">
Roesler, O. 2013. <span>“<span>EEG Eye State</span> [Dataset].”</span> UCI Machine Learning Repository. <a href="https://doi.org/10.24432/C57G7J">https://doi.org/10.24432/C57G7J</a>.
</div>
<div id="ref-tesla_autopilot" class="csl-entry">
Tesla Support. n.d. <span>“Autopilot and Full Self-Driving (Supervised).”</span> <a href="https://www.tesla.com/support/autopilot">https://www.tesla.com/support/autopilot</a>.
</div>
<div id="ref-R-tidyverse" class="csl-entry">
Wickham, Hadley. 2023. <em>Tidyverse: Easily Install and Load the Tidyverse</em>. <a href="https://tidyverse.tidyverse.org">https://tidyverse.tidyverse.org</a>.
</div>
<div id="ref-R-ggplot2" class="csl-entry">
Wickham, Hadley, Winston Chang, Lionel Henry, Thomas Lin Pedersen, Kohske Takahashi, Claus Wilke, Kara Woo, Hiroaki Yutani, Dewey Dunnington, and Teun van den Brand. 2024. <em>Ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics</em>. <a href="https://ggplot2.tidyverse.org">https://ggplot2.tidyverse.org</a>.
</div>
</div>
</div>
</div>
</div>

</div>



</body>
</html>
