<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">


<!--
Font-awesome icons ie github or twitter
-->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/brands.css" integrity="sha384-n9+6/aSqa9lBidZMRCQHTHKJscPq6NW4pCQBiMmHdUCvPN8ZOg2zJJTkC7WIezWv" crossorigin="anonymous">

<!--
Google fonts api stuff
-->



<title>Predicting Cognitive States Through EEG Sensors and Machine Learning</title>






<style>
@page {
size: 45in 38in;
margin: 0;
padding: 0;
}
body {
margin: 0;
font-size: 45px;
width: 45in;
height: 38in;
padding: 0;
text-align: justify;
font-family: Palatino;
}
.poster_wrap {
width: 45in;
height: 38in;
padding: 0cm;
}
.title_container {
width: 45in;
height: calc(38in * 0.15);
overflow: hidden;
background-color: #0b4545;
border: 0 solid #0b4545;
}
.logo_left {
float: left;
width: 10%;
height: 100%;
background-color: #0b4545;
display: flex;
align-items: center;
justify-content: center;
}
.logo_right {
float: right;
width: 10%;
height: 100%;
background-color: #0b4545;
display: flex;
align-items: center;
justify-content: center;
}
.poster_title {
text-align: center;
position: relative;
float: left;
width: 80%;
height: 100%;
color: #FFFFFF;
top: 50%;
transform: translateY(-50%);
-webkit-transform: translateY(-50%);
}
#title {
font-family: Palatino;
}
/* unvisited link */
a:link {
color: #cc0000;
}
.mybreak {
  break-before: column;
}
/* visited link */
a:visited {
color: #cc0000;
}

/* mouse over link */
a:hover {
color: #cc0000;
}

/* selected link */
a:active {
color: #cc0000;
}
.poster_body {
-webkit-column-count: 3; /* Chrome, Safari, Opera */
-moz-column-count: 3; /* Firefox */
column-count: 3;
-webkit-column-fill: auto;
-moz-column-fill: auto;
column-fill: auto;
-webkit-column-rule-width: 1mm;
-moz-column-rule-width: 1mm;
column-rule-width: 1mm;
-webkit-column-rule-style: dashed;
-moz-column-rule-style: dashed;
column-rule-style: dashed;
-webkit-column-rule-color: #0b4545;
-moz-column-rule-color: #0b4545;
column-rule-color: #0b4545;
column-gap: 1em;
padding-left: 0.5em;
padding-right: 0.5em;
height: 100%;
color: #000000
background-color: #ffffff;
}
.poster_title h1 {
font-size: 75pt;
margin: 0;
border: 0;
font-weight: normal;
}
.poster_body_wrap{
width: calc(45in + 0 + 0);
height: calc(38in * 0.83);
padding-top: calc(38in * 0.005);
padding-bottom: calc(38in * 0.01);
background-color: #ffffff;
}
.poster_title h3 {
color: #ffffff;
font-size: 50pt;
margin: 0;
border: 0;
font-weight: normal;
}
.poster_title h3 > sup {
  font-size: 35pt;
  margin-left: 0.02em;
}
.poster_title h5 {
color: #FFFFFF;
font-size: 35pt;
margin: 0;
border: 0;
font-weight: normal;
}
img {
margin-top: 2cm;
margin-bottom: 0;
}
.section {
  padding: 0.2em;
}
.poster_body h1 {
text-align: center;
color: #FFFFFF;
font-size: 65pt;
border: 2mm solid #0b4545;
background-color: #0b4545;
border-radius: 4mm 0mm;
margin-top: 2mm;
margin-bottom: 2mm;
font-weight: normal;
}
.poster_body h2 {
color: #000000;
font-size: 40pt;
padding-left: 4mm;
font-weight: normal;
}
.span {
width: 200%;
}
/* center align leaflet map,
from https://stackoverflow.com/questions/52112119/center-leaflet-in-a-rmarkdown-document */
.html-widget {
margin: auto;
position: sticky;
margin-top: 2cm;
margin-bottom: 2cm;
}
.leaflet.html-widget.html-widget-static-bound.leaflet-container.leaflet-touch.leaflet-fade-anim.leaflet-grab.leaflet-touch-drag.leaflet-touch-zoom {
position: sticky;
width: 100%;
}
pre.sourceCode.r {
background-color: #dddddd40;
border-radius: 4mm;
padding: 4mm;
width: 75%;
/* align-items: center; */
margin: auto;
padding-left: 2cm;
}
code.sourceCode.r{
background-color: transparent;
font-size: 20pt;
border-radius: 2mm;
}
.caption {
font-size: 25pt;
}
.table caption {
font-size: 25pt;
padding-bottom: 3mm;

}
code {
font-size: 1em;
font-family: monospace;
background-color: #00808024;
color: #0b4545;
padding: 1.2mm;
border-radius: 2mm;
}
.poster_title code {
font-size: 1em;
}
table {
font-size: 40px;
margin: auto;
border-top: 3px solid #666;
border-bottom: 3px solid #666;
}
table thead th {
border-bottom: 3px solid #ddd;
}
td {
padding: 8px;
}
th {
padding: 15px;
}
caption {
margin-bottom: 10px;
}
.poster_body p {
margin-right: 4mm;
margin-left: 4mm;
margin-top: 6mm;
margin-bottom: 10mm;
}
.poster_body ol {
margin-right: 4mm;
margin-left: 4mm;
}
#ul {
margin-right: 4mm;
margin-left: 4mm;
}
.references p {
font-size: 20pt;
}
.orcid img {
  width: 1em;
}
</style>
</head>
<body>


<div class="poster_wrap">
<div class="title_container">
<!-- Left Logo  -->
<div class="logo_left">
</div>
<!-- Poster Title -->
<div class= "poster_title">
<h1 id="title">Predicting Cognitive States Through EEG Sensors and Machine Learning</h1>
<h3 id="author">Vincent Espana<sup>1</sup></h3><br>
<h5 id="affiliation"><sup>1</sup> Department of Cognitive Science, Rutgers University</h5>
</div>
<!-- Right Logo  -->
<div class="logo_right">
</div>
</div>

<div class='poster_body_wrap'>
<div class='poster_body'>
<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p>As AI technologies and machine learning continue to advance, its integration into everyday life has exponentially increased in recent years. One of the many examples of this is Tesla Autopilot and Full Self-Driving, whose semi-autonomous technologies allows cars to accelarate, make turns, and even parallel park! Yet, this innovative technology still requires an active driver at the wheel and accounts for yawning, blinking, and many more fatigue indicators to track the driver’s current cognitive state. This research project aims to investigate brainwave activity, in hopes that a machine learning model, such as Tesla Autopilot and Full Self-Driving, can better predict a driver’s cognitive state.</p>
</div>
<div id="research-question" class="section level1">
<h1>Research Question</h1>
<p>How do <strong>variations</strong> in EEG sensor values between open and closed eye states reflect changes in brainwave activities, and how can this information be used to train machine learning models for <strong>accurately predicting</strong> cognitive states like attention and mental fatigue?</p>
<p>More specifically, this research aims to determine which sensors are <strong>most predictive</strong> of cognitive state during open and closed eye states.</p>
</div>
<div id="data-source" class="section level1">
<h1>Data Source</h1>
<p>The dataset used in this study is the <em>EEG Eye State</em> database from the UC Irvine Machine Learning Repository. It contains EEG recordings from <strong>14</strong> different EEG sensors, in which participants were asked to perform tasks with either their eyes <strong>open</strong> (0) or <strong>closed</strong> (1). These sensors are positioned on different areas of the head to measure brainwave activity corresponding to various brain lobes. Each lobe has distinct functions:</p>
<ul>
<li>Frontal Lobe: Responsible for decision-making, emotional regulation, and attention</li>
<li>Fronto-Central Lobe: Plays a key role in motor control</li>
<li>Temporal Lobe: Involved in hearing, language recognition, and memory</li>
<li>Parietal Lobe: Processes sensory information, such as touch, temperature, pressure, and pain</li>
<li>Occipital Lobe: Specializes in visual processing</li>
</ul>
<div class="figure"><span style="display:block;" id="fig:eeg-image"></span>
<img src="electrodespos.png" alt="EEG Sensors"  />
<p class="caption">
Figure 1: EEG Sensors
</p>
</div>
</div>
<div id="results-and-interpretation" class="section level1">
<h1>Results and Interpretation</h1>
<ol style="list-style-type: decimal">
<li>Does average EEG sensor values between eye states vary across the different sensors?</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot1"></span>
<img src="FinalProj_files/figure-html/plot1-1.png" alt="Average EEG Values Across Sensors Separated By Eye State" width="960" />
<p class="caption">
Figure 2: Average EEG Values Across Sensors Separated By Eye State
</p>
</div>
<p>This plot compares the mean signal value of each sensor for both open and closed eye states. Excluding the F8 sensor, the average signal value for all sensors for open eye states were less than or equal to the average signal value for closed eye states. Some sensors that seem particularly important are the AF3, AF4, F8, and FC6 sensors, as they had the largest average difference in signal values between open and closed eye states.</p>
<ol start="2" style="list-style-type: decimal">
<li>Are the visual processing (O1 and O2) sensors indicative of cognitive state?</li>
</ol>
<table>
<caption><span id="tab:table">Table 1: </span>Summary Statistics for Sensors O1 and O2</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Min.</th>
<th align="right">Max.</th>
<th align="right">Mean</th>
<th align="right">Std. Dev.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">O1 Open</td>
<td align="right">4027.18</td>
<td align="right">4178.46</td>
<td align="right">4071.973</td>
<td align="right">17.80437</td>
</tr>
<tr class="even">
<td align="left">O1 Closed</td>
<td align="right">4026.15</td>
<td align="right">4167.18</td>
<td align="right">4073.866</td>
<td align="right">24.14483</td>
</tr>
<tr class="odd">
<td align="left">O2 Open</td>
<td align="right">4567.18</td>
<td align="right">4731.79</td>
<td align="right">4614.925</td>
<td align="right">18.21651</td>
</tr>
<tr class="even">
<td align="left">O2 Closed</td>
<td align="right">4567.69</td>
<td align="right">4770.26</td>
<td align="right">4616.872</td>
<td align="right">18.53288</td>
</tr>
</tbody>
</table>
<p>This table provides summary statistics for the O1 and O2 sensors, which are specific to visual processing. The resulting values contained in this table do not provide any indication of whether or not these sensors are particularly important when predicting cognitive state, as the minimum, maximum, and mean signal values were similar across open and closed eye states. The standard deviation of the O1 sensor with a closed eye state is significantly higher than the others, alluding that the distribution of values might be important to investigate.</p>
<ol start="3" style="list-style-type: decimal">
<li>What do frontal lobe sensors tell us and how can this information be used to by machine learning models to predict cognitive state?</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot2"></span>
<img src="FinalProj_files/figure-html/plot2-1.png" alt="Median Signal Value and Variability of AF3 Sensor" width="960" />
<p class="caption">
Figure 3: Median Signal Value and Variability of AF3 Sensor
</p>
</div>
<p>This plot further investigates the AF3 sensor. This sensor tells us that the range of signal values may be more significant that the mean signal value. Therefore, machine learning models working to predict cognitive states should investigate the underlying distribution of signal values across different sensors in order to accurately predict cognitive state.</p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>This research explored the relationship between open and closed eye states and EEG signal values across multiple sensors. Results consistently demonstrated that closed eye states produced a slightly higher mean signal value compared to open eye states. In addition, investigating specific sensors showed that the range of signal values for open states are much larger than that of closed states. For machine learning models to better predict a driver’s cognitive state based on brainwave activity, it is important to place an emphasis on these findings as it may aid in improving semi-autonomous functions, such as Tesla Autopilot and Full Self-Driving.</p>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ol style="list-style-type: decimal">
<li>Autopilot and full self-driving (supervised): Tesla Support. Tesla. (n.d.). <a href="https://www.tesla.com/support/autopilot" class="uri">https://www.tesla.com/support/autopilot</a></li>
<li>Eeg Eye State. UCI Machine Learning Repository. (n.d.). <a href="https://archive.ics.uci.edu/dataset/264/eeg+eye+state" class="uri">https://archive.ics.uci.edu/dataset/264/eeg+eye+state</a></li>
<li>Hou, X. (2015, October). Location of 14 electrodes of emotiv EEG device. | download scientific diagram. ResearchGate. <a href="https://www.researchgate.net/figure/Location-of-14-electrodes-of-Emotiv-EEG-device_fig1_283441559" class="uri">https://www.researchgate.net/figure/Location-of-14-electrodes-of-Emotiv-EEG-device_fig1_283441559</a></li>
</ol>
</div>
</div>
</div>

</div>



</body>
</html>
